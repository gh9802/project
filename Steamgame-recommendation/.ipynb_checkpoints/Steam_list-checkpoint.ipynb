{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now >>>>> (1) in: 2020-12-04 18:51:05.105986\n",
      "href Pass!\n",
      "https://store.steampowered.com/app/730/CounterStrike_Global_Offensive/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1085660/Destiny_2/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/359550/Tom_Clancys_Rainbow_Six_Siege/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1263850/Football_Manager_2021/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1172470/Apex_Legends/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/578080/PLAYERUNKNOWNS_BATTLEGROUNDS/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/381210/Dead_by_Daylight/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/271590/Grand_Theft_Auto_V/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/739630/Phasmophobia/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/594570/Total_War_WARHAMMER_II/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1174180/Red_Dead_Redemption_2/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/945360/Among_Us/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/648800/Raft/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/230410/Warframe/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/582010/Monster_Hunter_World/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/552990/World_of_Warships/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1097150/Fall_Guys_Ultimate_Knockout/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/526870/Satisfactory/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1313860/EA_SPORTS_FIFA_21/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1315750/Total_War_WARHAMMER_II__The_Twisted__The_Twilight/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/413150/Stardew_Valley/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/1145360/Hades/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/236390/War_Thunder/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/958260/DEAD_OR_ALIVE_Xtreme_Venus_Vacation/?snr=1_7_7_230_150_1\n",
      "https://store.steampowered.com/app/322330/Dont_Starve_Together/?snr=1_7_7_230_150_1\n",
      "end in: 2020-12-04 18:51:26.558830\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver as webDriver\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "import datetime\n",
    "\n",
    "def catch(url):\n",
    "    try_flag = True\n",
    "    while(try_flag):\n",
    "        try:\n",
    "            html = urlopen(url)\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            #print(soup.prettify())\n",
    "            try_flag = False\n",
    "            return soup\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            \n",
    "def catch_sel(url):\n",
    "    try_flag = True\n",
    "    while(try_flag):\n",
    "        try:\n",
    "            driver.get(url)\n",
    "            try_flag = False\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            driver.refresh()\n",
    "\n",
    "flag = True\n",
    "page = START = 1 ### 시작 페이지\n",
    "END = 2 ### 끝 페이지 - 1\n",
    "\n",
    "TITLE, GENRE, DEV, PUB, RED, USER_SCORE, SCORE, TAG, URL, FR = [], [], [], [], [], [], [], [], [], []\n",
    "\n",
    "firefox_dir = r'C:\\Users\\ghc11\\Desktop\\geckodriver-v0.28.0-win64\\geckodriver.exe'\n",
    "driver = webDriver.Firefox(executable_path=firefox_dir)\n",
    "#driver.get(\"https://store.steampowered.com/search/?sort_by=Relevance_ASC&page=1\")\n",
    "\n",
    "while(flag):\n",
    "    print(\"now >>>>> (\" + str(page) + \") in: \" + str(datetime.datetime.now()))\n",
    "    \n",
    "    soup = catch(\"https://store.steampowered.com/search/?sort_by=_ASC&page=\" + str(page))\n",
    "            \n",
    "    #driver.get(\"https://store.steampowered.com/search/?term=ea+play&page=1\")\n",
    "    \n",
    "    #url = 'https://store.steampowered.com/search/?sort_by=_ASC&page=' + str(page)\n",
    "    #headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    #request = Request(url, headers = headers)\n",
    "    \n",
    "    #html = urlopen(request)\n",
    "    #soup = BeautifulSoup(html, 'html.parser')\n",
    "    #soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    \n",
    "    while(1):\n",
    "        href = soup.find('div', {'id':\"search_resultsRows\"})\n",
    "        if href != None:\n",
    "            print(\"href Pass!\")\n",
    "            break;\n",
    "        else:\n",
    "            print(\"href Error!\")\n",
    "            #url = 'https://store.steampowered.com/search/?sort_by=_ASC&page=' + str(page)\n",
    "            #headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "            #request = Request(url, headers = headers)\n",
    "\n",
    "            #html = urlopen(request)\n",
    "            \n",
    "            soup = catch(\"https://store.steampowered.com/search/?sort_by=Relevance_ASC&page=\" + str(page))\n",
    "        \n",
    "    href2 = href.find_all('span', 'title')\n",
    "\n",
    "    for i in href2:\n",
    "        TITLE.append(i.text)\n",
    "    \n",
    "    href3 = href.find_all('a', href=True)\n",
    "\n",
    "    for i in href3:\n",
    "        temp_flag = False\n",
    "        \n",
    "        URL.append(i['href'])\n",
    "        \n",
    "        url = i['href']\n",
    "        #headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        #request = Request(url, headers = headers)\n",
    "        \n",
    "        soup = catch(url)\n",
    "        print(url)\n",
    "        \n",
    "        #html = urlopen(request)\n",
    "        #soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        while(1):\n",
    "            detail = soup.find_all('div', 'block_content_inner')\n",
    "            checker = True\n",
    "            if len(detail) != 0:\n",
    "                #print(\"detail Pass!\")\n",
    "                for i in detail:\n",
    "                    if i.find('div', 'details_block') != None:\n",
    "                        detail = i.find('div', 'details_block')\n",
    "                        checker = False\n",
    "                        break;\n",
    "                if not checker:\n",
    "                    break;\n",
    "                    \n",
    "            else:\n",
    "                #print(\" href Error!\")\n",
    "                #url = i['href']\n",
    "                #headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "                #request = Request(url, headers = headers)\n",
    "\n",
    "                #html = urlopen(request)\n",
    "                #soup = BeautifulSoup(html, 'html.parser')\n",
    "                \n",
    "                catch_sel(url)\n",
    "                soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                \n",
    "                if soup.find('div', 'SaleSectionCtn') != None:\n",
    "                    GENRE.append(\" \")\n",
    "                    DEV.append(\" \")\n",
    "                    PUB.append(\" \")\n",
    "                    RED.append(\" \")\n",
    "                    USER_SCORE.append(\" \")\n",
    "                    SCORE.append(\" \")\n",
    "                    TAG.append(\" \")\n",
    "                    FR.append(\" \")\n",
    "                    temp_flag = True\n",
    "                    break;\n",
    "\n",
    "                if soup.find('div', 'agegate_birthday_selector') != None:\n",
    "                    #print(\"19+ Detected\")\n",
    "                    driver.find_element_by_xpath('''//*[@id=\"ageDay\"]''').send_keys('9')\n",
    "                    driver.find_element_by_xpath('''//*[@id=\"ageMonth\"]''').send_keys('April')\n",
    "                    driver.find_element_by_xpath('''//*[@id=\"ageYear\"]''').send_keys('1997')\n",
    "                    driver.find_element_by_class_name('''btnv6_blue_hoverfade''').click()\n",
    "                    time.sleep(5)\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                \n",
    "                else:\n",
    "                    count += 1\n",
    "                    driver.refresh()\n",
    "                    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "                    \n",
    "                    if count > 20:\n",
    "                        GENRE.append(\" \")\n",
    "                        DEV.append(\" \")\n",
    "                        PUB.append(\" \")\n",
    "                        RED.append(\" \")\n",
    "                        USER_SCORE.append(\" \")\n",
    "                        SCORE.append(\" \")\n",
    "                        TAG.append(\" \")\n",
    "                        FR.append(\" \")\n",
    "                        temp_flag = True\n",
    "                        break;\n",
    "                    #soup = catch(url)\n",
    "        \n",
    "        \n",
    "        if temp_flag:\n",
    "            continue;\n",
    "        #detail = soup.find('div', 'block_content_inner').find('div', 'details_block')\n",
    "        temp = re.split(r'[\\n:]', (detail.text.strip()))\n",
    "\n",
    "        temp = [i for i in temp if i]\n",
    "        temp2 = []\n",
    "\n",
    "        for i in temp:\n",
    "            temp2.append(i.strip())\n",
    "\n",
    "        if 'Franchise' in temp2:\n",
    "            FR.append(temp2[temp2.index('Franchise') + 1])\n",
    "        else:\n",
    "            FR.append(\" \")\n",
    "        \n",
    "        if 'Genre' in temp2:\n",
    "            GENRE.append(temp2[temp2.index('Genre') + 1])\n",
    "        else:\n",
    "            GENRE.append(\" \")\n",
    "            \n",
    "        if 'Developer' in temp2:\n",
    "            DEV.append(temp2[temp2.index('Developer') + 1])\n",
    "        else:\n",
    "            DEV.append(\" \")\n",
    "        \n",
    "        if 'Publisher' in temp2:\n",
    "            PUB.append(temp2[temp2.index('Publisher') + 1])\n",
    "        else:\n",
    "            PUB.append(\" \")\n",
    "        \n",
    "        if 'Release Date' in temp2:\n",
    "            RED.append(temp2[temp2.index('Release Date') + 1])\n",
    "        else:\n",
    "            RED.append(\" \")\n",
    "\n",
    "        #print(\": \".join(temp2))\n",
    "        \n",
    "        if soup.find('span', 'game_review_summary') != None:\n",
    "            USER_SCORE.append(soup.find('span', 'game_review_summary').text)\n",
    "        else:\n",
    "            USER_SCORE.append(\" \")\n",
    "\n",
    "        raw_TAG = []\n",
    "        \n",
    "        if soup.find('div', 'glance_tags') != None:\n",
    "            user_tag = soup.find('div', 'glance_tags').find_all('a', href=True)\n",
    "            for i in user_tag:\n",
    "                raw_TAG.append(i.text.strip())\n",
    "\n",
    "            TAG.append(\", \".join(raw_TAG))\n",
    "        else:\n",
    "            TAG.append(\" \")\n",
    "\n",
    "        if soup.find('div', {'id':'game_area_metascore'}) != None and soup.find('div', {'id':'game_area_metascore'}).find('div', 'score') != None:\n",
    "            #print(\"test\")\n",
    "            SCORE.append(soup.find('div', {'id':'game_area_metascore'}).find('div', 'score').text.strip())\n",
    "        else:\n",
    "            SCORE.append(\" \")\n",
    "    \n",
    "    page += 1\n",
    "    \n",
    "    if(page == END):\n",
    "        flag = False\n",
    "        \n",
    "print(\"end in: \" + str(datetime.datetime.now()))\n",
    "\n",
    "csvFile = open('test_' + str(START) + \"_\" + str(END) + '.csv', 'w+', newline='', encoding=\"utf-8-sig\")\n",
    "\n",
    "try:\n",
    "    writer = csv.writer(csvFile)\n",
    "    writer.writerow(('Name', 'Genre', 'Developer', 'Publisher', 'Franchise', 'Release Date', 'User score', 'Meta score', 'User tag', 'Url'))\n",
    "    for Title, Genre, Dev, Pub, Fr, Red, User_score, Score, Tag, Url in zip(TITLE, GENRE, DEV, PUB, FR, RED, USER_SCORE, SCORE, TAG, URL):\n",
    "        writer.writerow((Title, Genre, Dev, Pub, Fr, Red, User_score, Score, Tag, Url))\n",
    "finally:\n",
    "    csvFile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
